{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = glob(os.path.join(os.getenv(\"HOME\"), \"data/rock_scissor_paper/train/*/*/*\"))\n",
    "test_path = glob(os.path.join(os.getenv(\"HOME\"), \"data/rock_scissor_paper/test/*/*/*\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total image size : 4317\n"
     ]
    }
   ],
   "source": [
    "data_size = len(train_path) + len(test_path)\n",
    "print(f\"Total image size : {data_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_img(img, img_size, color):\n",
    "    new_img = np.reshape(img, (img_size,img_size, color))\n",
    "    return new_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(img_path, num_data):\n",
    "    #불러올 폴더 내에 존재하는 데이터 정보\n",
    "    number_of_data = num_data\n",
    "    img_size = 28\n",
    "    color = 3\n",
    "    \n",
    "    imgs = np.zeros(number_of_data*img_size*img_size*color, dtype=np.int32).reshape(number_of_data, img_size, img_size, color)\n",
    "    labels = np.zeros(number_of_data, dtype = np.int32)\n",
    "    \n",
    "    idx=0\n",
    "    for file in glob(img_path+'*/*/scissor/*'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        img = resize_img(img, img_size, color)\n",
    "        imgs[idx,:,:,:]=img   # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "    \n",
    "    for file in glob(img_path+'*/*/rock/*'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        img = resize_img(img, img_size, color)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1\n",
    "    \n",
    "    for file in glob(img_path+'*/*/paper/*'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        img = resize_img(img, img_size, color)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx = idx+1\n",
    "\n",
    "    return imgs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = os.getenv(\"HOME\")+\"/data/rock_scissor_paper/\"\n",
    "(img, label) = load_data(data_dir, data_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, '2')"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(img[4300])\n",
    "plt.title(label[4300], loc='center')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = img/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 0.0)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(img), np.min(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(img, label, test_size=0.1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (3885, 28, 28, 3)\n",
      "y_train shape: (3885,)\n"
     ]
    }
   ],
   "source": [
    "#학습 데이터의 사이즈를 확인한다.\n",
    "print(\"x_train shape: {}\".format(x_train.shape))\n",
    "print(\"y_train shape: {}\".format(y_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_test shape: (432, 28, 28, 3)\n",
      "y_test shape: (432,)\n"
     ]
    }
   ],
   "source": [
    "#test data의 shape을 확인한다.\n",
    "print(\"x_test shape: {}\".format(x_test.shape))\n",
    "print(\"y_test shape: {}\".format(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 26, 26, 64)        1792      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 11, 11, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 4803      \n",
      "=================================================================\n",
      "Total params: 43,523\n",
      "Trainable params: 43,523\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(28,28,3), activity_regularizer=tf.keras.regularizers.l2(0.01)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(64, (3,3), activation='relu',activity_regularizer=tf.keras.regularizers.l2(0.01)))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NO\n",
      "Physical devices cannot be modified after being initialized\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(\"NO\")\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.experimental.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "110/110 [==============================] - 5s 41ms/step - loss: 2.1886 - accuracy: 0.3830 - val_loss: 1.1498 - val_accuracy: 0.4961\n",
      "Epoch 2/10\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 1.1080 - accuracy: 0.5506 - val_loss: 1.0842 - val_accuracy: 0.5835\n",
      "Epoch 3/10\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 1.0579 - accuracy: 0.6053 - val_loss: 1.0180 - val_accuracy: 0.6504\n",
      "Epoch 4/10\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.9662 - accuracy: 0.6931 - val_loss: 0.9002 - val_accuracy: 0.7481\n",
      "Epoch 5/10\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.8482 - accuracy: 0.7666 - val_loss: 0.7909 - val_accuracy: 0.7892\n",
      "Epoch 6/10\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.7455 - accuracy: 0.8118 - val_loss: 0.7175 - val_accuracy: 0.8021\n",
      "Epoch 7/10\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.6582 - accuracy: 0.8412 - val_loss: 0.6305 - val_accuracy: 0.8380\n",
      "Epoch 8/10\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.6002 - accuracy: 0.8541 - val_loss: 0.5878 - val_accuracy: 0.8483\n",
      "Epoch 9/10\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.5541 - accuracy: 0.8633 - val_loss: 0.5356 - val_accuracy: 0.8535\n",
      "Epoch 10/10\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.5155 - accuracy: 0.8773 - val_loss: 0.5026 - val_accuracy: 0.8638\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f52908a6e50>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate=0.0003), loss = 'sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, epochs = 10, batch_size = 32, validation_split = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 - 1s - loss: 0.5104 - accuracy: 0.8750\n",
      "test_loss: 0.5103816390037537 \n",
      "test_accuracy: 0.875\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(x_test, y_test, verbose=2)\n",
    "print(\"test_loss: {} \".format(test_loss))\n",
    "print(\"test_accuracy: {}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "432\n",
      "[0 1 0 1 1 2 2 1 1 1 1 0 2 1 2 0 0 0 1 2 1 2 1 1 1 2 1 0 1 1 1 0 2 2 1 1 0\n",
      " 1 0 1 1 0 1 0 1 1 1 1 1 2 1 1 2 2 2 1 0 0 1 0 1 1 0 2 1 2 2 1 1 0 1 1 0 1\n",
      " 1 1 1 0 1 2 2 1 1 1 1 1 1 2 0 0 1 2 0 1 2 2 0 2 0 1 0 2 1 0 2 2 0 1 2 0 1\n",
      " 2 2 2 0 1 0 1 0 1 1 1 1 2 1 2 1 0 0 0 2 0 1 2 2 2 1 1 1 2 2 2 0 2 2 1 1 1\n",
      " 2 0 2 0 1 0 0 1 0 2 1 0 1 0 1 1 1 1 0 0 0 2 1 0 0 2 0 2 1 2 1 1 1 1 1 2 1\n",
      " 2 2 1 2 0 1 1 1 2 1 2 1 2 0 1 0 1 0 1 0 0 2 1 2 0 2 1 1 2 0 1 1 2 2 0 2 2\n",
      " 1 2 0 0 0 1 1 1 2 2 0 0 1 2 1 0 0 2 1 0 0 1 2 2 1 1 1 2 0 1 1 1 2 2 0 0 1\n",
      " 2 2 2 0 0 1 1 0 2 1 1 1 2 1 1 2 2 1 2 2 0 1 2 0 2 0 2 2 1 2 0 1 2 2 0 0 1\n",
      " 1 1 2 0 1 1 0 2 1 2 0 1 1 0 2 2 0 0 1 0 1 0 0 0 0 0 1 0 2 0 0 0 0 2 0 1 2\n",
      " 1 2 1 1 1 1 0 2 1 2 2 2 1 0 0 1 0 0 0 1 0 1 2 0 0 0 1 1 2 1 0 1 0 1 2 0 1\n",
      " 0 2 1 0 1 0 0 2 1 0 1 1 1 0 2 0 0 2 1 0 2 1 2 1 0 0 1 0 2 2 0 0 2 2 2 1 0\n",
      " 1 1 0 0 2 2 1 2 1 2 2 1 1 2 0 1 1 1 1 2 1 1 0 2 1]\n"
     ]
    }
   ],
   "source": [
    "predicted_result = model.predict(x_test)  # model이 추론한 확률값. \n",
    "predicted_labels = np.argmax(predicted_result, axis=1)\n",
    "print(len(predicted_labels))\n",
    "print(predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
